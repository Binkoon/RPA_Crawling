### í•´ë‹¹ ì½”ë“œ ì—­í•  ìš”ì•½ ###
# ì‹¤ì œ ì—­í• :
# - ì„¤ì • íŒŒì¼ì—ì„œ ì„ ì‚¬ ëª©ë¡ ë¡œë“œ
# - í¬ë¡¤ëŸ¬ íŒ©í† ë¦¬ í˜¸ì¶œí•˜ì—¬ í¬ë¡¤ëŸ¬ ìƒì„±
# - ê°œë³„ í¬ë¡¤ëŸ¬ ì‹¤í–‰ ë° ì—ëŸ¬ ì²˜ë¦¬
# - ê²°ê³¼ ì§‘ê³„ ë° ë¡œê¹…
# - Excel ë¡œê·¸ ìƒì„±
# - êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ í˜¸ì¶œ
# - ë°ì´í„° ì •ë¦¬ ìŠ¤í¬ë¦½íŠ¸ í˜¸ì¶œ
# - ì—ëŸ¬ë¡œê·¸ ìë™ ì—…ë¡œë“œ ë° ì •ë¦¬

# í•˜ì§€ ì•ŠëŠ” ê²ƒ:
# - ì§ì ‘ í¬ë¡¤ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±í•˜ì§€ ì•ŠìŒ
# - ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì§ì ‘ ê´€ë¦¬í•˜ì§€ ì•ŠìŒ


# ì—¬ê¸°ì„œë¶€í„° ì‹œì‘í•¨.
from crawler import base
from crawler import sitc
from crawler import evergreen
from crawler import cosco
from crawler import wanhai
from crawler import one
from crawler import ckline
from crawler import panocean
from crawler import snl
from crawler import smline
from crawler import hmm
from crawler import fdt
from crawler import ial # ì™„ë£Œ
from crawler import dyline
from crawler import yml  # ì™„ë£Œ
from crawler import nss

import traceback
import logging
from datetime import datetime
import os
import sys
import pandas as pd
import shutil
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed

# ErrorLog í´ë” êµ¬ì¡° ìƒì„±
def setup_errorlog_folder():
    """ErrorLog í´ë” êµ¬ì¡° ìƒì„±"""
    log_base_dir = os.path.join(os.getcwd(), "ErrorLog")
    if not os.path.exists(log_base_dir):
        os.makedirs(log_base_dir)
    
    # ë‚ ì§œë³„ í´ë” ìƒì„± (YYYY-MM-DD í˜•ì‹)
    today_log_folder = datetime.now().strftime("%Y-%m-%d")
    today_log_dir = os.path.join(log_base_dir, today_log_folder)
    if not os.path.exists(today_log_dir):
        os.makedirs(today_log_dir)
    
    return today_log_dir

# ErrorLog í´ë” ì„¤ì •
today_log_dir = setup_errorlog_folder()

# ì—ëŸ¬ë¡œê·¸ êµ¬ê¸€ë“œë¼ì´ë¸Œ í´ë” ID
ERRORLOG_DRIVE_FOLDER_ID = '1t3P2oofZKnSrVMmDS6-YQcwuZC6PdCz5'

# ë©”ì¸ ë¡œê¹… ì„¤ì • (ì½˜ì†”ë§Œ)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler()
    ]
)

# í¬ë¡¤ëŸ¬ íŒ©í† ë¦¬ import
from crawler_factory import CrawlerFactory

# Google Drive ê´€ë ¨ í•¨ìˆ˜ë“¤ import
import sys
sys.path.append(os.path.join(os.getcwd(), 'Google'))
from Google.upload_to_drive_oauth import get_drive_service, upload_file_to_drive

# ë¹Œë” íŒ¨í„´ì„ ìœ„í•œ í¬ë¡¤ë§ í”„ë¡œì„¸ìŠ¤ í´ë˜ìŠ¤
class CrawlingProcess:
    """í¬ë¡¤ë§ í”„ë¡œì„¸ìŠ¤ì˜ ìµœì¢… ê²°ê³¼ë¥¼ ë‹´ëŠ” í´ë˜ìŠ¤"""
    def __init__(self):
        self.crawling_results = []
        self.total_duration = 0
        self.success_count = 0
        self.fail_count = 0
        self.total_vessels_success = 0
        self.total_vessels_fail = 0
        self.excel_log_path = None
        self.upload_result = None
        self.cleanup_result = None

class CrawlingProcessBuilder:
    """í¬ë¡¤ë§ í”„ë¡œì„¸ìŠ¤ë¥¼ ë‹¨ê³„ë³„ë¡œ êµ¬ì„±í•˜ëŠ” ë¹Œë” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.process = CrawlingProcess()
        self.carriers_config = None
        self.max_workers = 2
        self.logger = None
        self.total_start_time = None
        self.total_end_time = None
    
    def setup_environment(self):
        """í™˜ê²½ ì„¤ì • ë‹¨ê³„: í´ë” ìƒì„±, ì„¤ì • ë¡œë“œ, ë¡œê¹… ì„¤ì •"""
        print("í™˜ê²½ ì„¤ì • ë‹¨ê³„ ì‹œì‘")
        
        # ErrorLog í´ë” ì„¤ì •
        self.process.today_log_dir = setup_errorlog_folder()
        
        # ë¡œê±° ì„¤ì •
        self.logger = logging.getLogger(__name__)
        
        # ì„¤ì • íŒŒì¼ ë¡œë“œ
        self.carriers_config = load_carriers_config()
        
        print("í™˜ê²½ ì„¤ì • ë‹¨ê³„ ì™„ë£Œ")
        return self
    
    def configure_threading(self, max_workers=2):
        """ìŠ¤ë ˆë“œ ì„¤ì • ë‹¨ê³„: ë³‘ë ¬ ì²˜ë¦¬ ì„¤ì •"""
        self.max_workers = max_workers
        print(f"ìŠ¤ë ˆë“œ ì„¤ì •: {max_workers}ê°œ ì›Œì»¤")
        return self
    
    def add_carriers(self, carriers_config=None):
        """ì„ ì‚¬ ì„¤ì • ë‹¨ê³„: í¬ë¡¤ë§í•  ì„ ì‚¬ ëª©ë¡ ì„¤ì •"""
        if carriers_config:
            self.carriers_config = carriers_config
        
        if not self.carriers_config:
            raise ValueError("ì„ ì‚¬ ì„¤ì •ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        carriers_to_run = []
        for carrier_info in self.carriers_config['carriers']:
            carrier_name = carrier_info['name']
            carriers_to_run.append(carrier_name)
        
        self.process.carriers_to_run = carriers_to_run
        print(f"ì„ ì‚¬ ì„¤ì • ì™„ë£Œ: {len(carriers_to_run)}ê°œ ì„ ì‚¬")
        return self
    
    def execute_crawling(self):
        """í¬ë¡¤ë§ ì‹¤í–‰ ë‹¨ê³„: ì‹¤ì œ í¬ë¡¤ë§ ìˆ˜í–‰"""
        if not hasattr(self.process, 'carriers_to_run'):
            raise ValueError("ì„ ì‚¬ ëª©ë¡ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        print("í¬ë¡¤ë§ ì‹¤í–‰ ë‹¨ê³„ ì‹œì‘")
        print(f"ì´ {len(self.process.carriers_to_run)}ê°œ ì„ ì‚¬ í¬ë¡¤ë§ ì‹œì‘")
        print(f"ìŠ¤ë ˆë“œ ìˆ˜: {self.max_workers}ê°œ (ì„ ì‚¬ {self.max_workers}ê°œì”© ë³‘ë ¬ ì²˜ë¦¬)")
        print("="*80)
        
        # ì „ì²´ í¬ë¡¤ë§ ì‹œì‘ ì‹œê°„
        self.total_start_time = datetime.now()
        self.logger.info(f"=== ì „ì²´ í¬ë¡¤ë§ ì‹œì‘: {self.total_start_time.strftime('%Y-%m-%d %H:%M:%S')} ===")
        
        # ìŠ¤ë ˆë“œ ê¸°ë°˜ ë³‘ë ¬ ì‹¤í–‰
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # ëª¨ë“  ì„ ì‚¬ë¥¼ ìŠ¤ë ˆë“œ í’€ì— ì œì¶œ
            future_to_carrier = {executor.submit(run_carrier_parallel, carrier_name): carrier_name 
                               for carrier_name in self.process.carriers_to_run}
            
            # ì™„ë£Œëœ ì‘ì—…ë“¤ì„ ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬
            for future in as_completed(future_to_carrier):
                carrier_name = future_to_carrier[future]
                try:
                    result = future.result()
                    self.process.crawling_results.append(result)
                    print(f" {carrier_name} ì™„ë£Œ - ìŠ¤ë ˆë“œì—ì„œ ë°˜í™˜ë¨")
                except Exception as e:
                    print(f" {carrier_name} ìŠ¤ë ˆë“œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                    self.process.crawling_results.append((carrier_name, {
                        'success': False,
                        'duration': 0,
                        'start_time': None,
                        'end_time': datetime.now(),
                        'error': f'ìŠ¤ë ˆë“œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}',
                        'traceback': traceback.format_exc()
                    }))
        
        # ì „ì²´ í¬ë¡¤ë§ ì¢…ë£Œ ì‹œê°„
        self.total_end_time = datetime.now()
        self.process.total_duration = (self.total_end_time - self.total_start_time).total_seconds()
        
        print("í¬ë¡¤ë§ ì‹¤í–‰ ë‹¨ê³„ ì™„ë£Œ")
        return self
    
    def generate_reports(self):
        """ë³´ê³ ì„œ ìƒì„± ë‹¨ê³„: ê²°ê³¼ ìš”ì•½ ë° Excel ë¡œê·¸ ìƒì„±"""
        print("ë³´ê³ ì„œ ìƒì„± ë‹¨ê³„ ì‹œì‘")
        
        # í¬ë¡¤ë§ ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        print("\n" + "="*80)
        print("í¬ë¡¤ë§ ê²°ê³¼ ìš”ì•½")
        print("="*80)
        
        success_count = 0
        fail_count = 0
        total_vessels_success = 0
        total_vessels_fail = 0
        
        for carrier_name, result in self.process.crawling_results:
            status = "ì„±ê³µ" if result['success'] else "ì‹¤íŒ¨"
            duration_str = f"({result['duration']:.2f}ì´ˆ)" if 'duration' in result else ""
            print(f"{carrier_name}: {status} {duration_str}")
            
            if result['success']:
                success_count += 1
                if 'success_count' in result:
                    total_vessels_success += result['success_count']
                    total_vessels_fail += result['fail_count']
                    print(f"  â””â”€ ì„ ë°•: ì„±ê³µ {result['success_count']}ê°œ, ì‹¤íŒ¨ {result['fail_count']}ê°œ")
            else:
                fail_count += 1
                if 'total_vessels' in result and 'fail_count' in result:
                    total_vessels_success += result.get('success_count', 0)
                    total_vessels_fail += result['fail_count']
                    print(f"  â””â”€ ì„ ë°•: ì„±ê³µ {result.get('success_count', 0)}ê°œ, ì‹¤íŒ¨ {result['fail_count']}ê°œ")
                    if result.get('failed_vessels'):
                        print(f"  â””â”€ ì‹¤íŒ¨í•œ ì„ ë°•: {', '.join(result['failed_vessels'])}")
                elif 'error' in result:
                    print(f"  â””â”€ ì—ëŸ¬: {result['error']}")
        
        print(f"\në³‘ë ¬ ì²˜ë¦¬ ê²°ê³¼:")
        print(f"ì´ {len(self.process.crawling_results)}ê°œ ì„ ì‚¬ ì¤‘")
        print(f"ì„±ê³µ: {success_count}ê°œ")
        print(f"ì‹¤íŒ¨: {fail_count}ê°œ")
        print(f"ì´ ì†Œìš”ì‹œê°„: {self.process.total_duration:.2f}ì´ˆ")
        
        # ê¸°ì¡´ ìˆœì°¨ ì²˜ë¦¬ì™€ ë¹„êµ (ì´ë¡ ì )
        estimated_sequential_time = self.process.total_duration * self.max_workers
        time_saved = estimated_sequential_time - self.process.total_duration
        print(f"ì˜ˆìƒ ìˆœì°¨ ì²˜ë¦¬ ì‹œê°„: {estimated_sequential_time:.2f}ì´ˆ")
        print(f"ì ˆì•½ëœ ì‹œê°„: {time_saved:.2f}ì´ˆ ({time_saved/estimated_sequential_time*100:.1f}%)")
        
        if total_vessels_success > 0 or total_vessels_fail > 0:
            print(f"\nì„ ë°•ë³„ ìƒì„¸ ê²°ê³¼:")
            print(f"ì´ ì„ ë°•: {total_vessels_success + total_vessels_fail}ê°œ")
            print(f"ì„±ê³µ: {total_vessels_success}ê°œ")
            print(f"ì‹¤íŒ¨: {total_vessels_fail}ê°œ")
        
        print("="*80)
        
        # ê²°ê³¼ ì €ì¥
        self.process.success_count = success_count
        self.process.fail_count = fail_count
        self.process.total_vessels_success = total_vessels_success
        self.process.total_vessels_fail = total_vessels_fail
        
        # ë¡œê·¸ íŒŒì¼ì—ë„ ìš”ì•½ ê¸°ë¡
        self.logger.info(f"=== ì „ì²´ í¬ë¡¤ë§ ì™„ë£Œ: {self.total_end_time.strftime('%Y-%m-%d %H:%M:%S')} ===")
        self.logger.info(f"ì´ ì†Œìš”ì‹œê°„: {self.process.total_duration:.2f}ì´ˆ")
        self.logger.info(f"ì„±ê³µ: {success_count}ê°œ ì„ ì‚¬, ì‹¤íŒ¨: {fail_count}ê°œ ì„ ì‚¬")
        if total_vessels_success > 0 or total_vessels_fail > 0:
            self.logger.info(f"ì„ ë°•ë³„ - ì„±ê³µ: {total_vessels_success}ê°œ, ì‹¤íŒ¨: {total_vessels_fail}ê°œ")
        
        # ì—‘ì…€ ë¡œê·¸ ì €ì¥
        save_excel_log(self.process.crawling_results, self.process.total_duration)
        
        print("ë³´ê³ ì„œ ìƒì„± ë‹¨ê³„ ì™„ë£Œ")
        return self
    
    def upload_to_drive(self):
        """ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ ë‹¨ê³„: êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ"""
        print("ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ ë‹¨ê³„ ì‹œì‘")
        
        print("\n" + "="*80)
        print("êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ ì‹œì‘")
        print("="*80)
        
        # êµ¬ê¸€ ì—…ë¡œë“œ ë¡œê·¸ë¥¼ ìœ„í•œ ë¦¬ìŠ¤íŠ¸
        google_upload_logs = []
        
        try:
            # Google í´ë”ì˜ ì—…ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ import
            sys.path.append(os.path.join(os.getcwd(), 'Google'))
            from Google.upload_to_drive_oauth import main as upload_to_drive_main, get_drive_service, upload_file_to_drive
        
            # ì—…ë¡œë“œ ì‹¤í–‰
            upload_result = upload_to_drive_main()
            
            # ì—…ë¡œë“œ ê²°ê³¼ë¥¼ ë¡œê·¸ì— ê¸°ë¡
            if upload_result and isinstance(upload_result, dict):
                for file_info in upload_result.get('uploaded_files', []):
                    google_upload_logs.append({
                        'ë‚ ì§œ': datetime.now().strftime('%Y/%m/%d/%H/%M/%S'),
                        'ì„ ì‚¬': 'Google Drive',
                        'ì„ ë°•': file_info.get('filename', 'ì•Œ ìˆ˜ ì—†ìŒ'),
                        'ìƒíƒœ': 'ì„±ê³µ',
                        'ì‚¬ìœ /ê²°ê³¼': f"ì—…ë¡œë“œ ì™„ë£Œ (íŒŒì¼ ID: {file_info.get('file_id', 'N/A')})",
                        'ì†Œìš”ì‹œê°„': 'N/A'
                    })
                
                for file_info in upload_result.get('failed_files', []):
                    google_upload_logs.append({
                        'ë‚ ì§œ': datetime.now().strftime('%Y/%m/%d/%H/%M/%S'),
                        'ì„ ì‚¬': 'Google Drive',
                        'ì„ ë°•': file_info.get('filename', 'ì•Œ ìˆ˜ ì—†ìŒ'),
                        'ìƒíƒœ': 'ì‹¤íŒ¨',
                        'ì‚¬ìœ /ê²°ê³¼': f"ì—…ë¡œë“œ ì‹¤íŒ¨: {file_info.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}",
                        'ì†Œìš”ì‹œê°„': 'N/A'
                    })
            
            print("="*80)
            print("êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ ì™„ë£Œ")
            print("="*80)
            
            # êµ¬ê¸€ ì—…ë¡œë“œ ë¡œê·¸ë¥¼ ì—‘ì…€ì— ì¶”ê°€
            excel_log_data.extend(google_upload_logs)
            
            self.process.upload_result = upload_result
            
        except Exception as e:
            error_msg = f"êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}"
            print(error_msg)
            self.logger.error(error_msg)
            self.logger.error(f"ìƒì„¸ ì—ëŸ¬: {traceback.format_exc()}")
            
            # ì—…ë¡œë“œ ì‹¤íŒ¨ ë¡œê·¸ë¥¼ ì—‘ì…€ì— ì¶”ê°€
            google_upload_logs.append({
                'ë‚ ì§œ': datetime.now().strftime('%Y/%m/%d/%H/%M/%S'),
                'ì„ ì‚¬': 'Google Drive',
                'ì„ ë°•': 'ì „ì²´ ì—…ë¡œë“œ',
                'ìƒíƒœ': 'ì‹¤íŒ¨',
                'ì‚¬ìœ /ê²°ê³¼': error_msg,
                'ì†Œìš”ì‹œê°„': 'N/A'
            })
            excel_log_data.extend(google_upload_logs)
        
        print("ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ ë‹¨ê³„ ì™„ë£Œ")
        return self
    
    def cleanup_resources(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ë‹¨ê³„: ì˜¤ë˜ëœ ë°ì´í„° ë° ì—ëŸ¬ë¡œê·¸ ì •ë¦¬"""
        print("ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ë‹¨ê³„ ì‹œì‘")
        
        # ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬
        print("\n" + "="*80)
        print("ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬ ì‹œì‘")
        print("="*80)
        
        try:
            from cleanup_old_data import cleanup_old_folders
            
            # 1ë‹¬(30ì¼) ì´ì „ í´ë”ë“¤ ì •ë¦¬
            cleanup_old_folders(days_to_keep=30)
            
            print("="*80)
            print("ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬ ì™„ë£Œ")
            print("="*80)
            
        except Exception as e:
            print(f"ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬ ì‹¤íŒ¨: {str(e)}")
            self.logger.error(f"ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬ ì‹¤íŒ¨: {str(e)}")
            self.logger.error(f"ìƒì„¸ ì—ëŸ¬: {traceback.format_exc()}")
        
        # ì—ëŸ¬ë¡œê·¸ ìë™ ì—…ë¡œë“œ ë° ì •ë¦¬
        print("\n" + "="*80)
        print("ì—ëŸ¬ë¡œê·¸ ìë™ ì—…ë¡œë“œ ë° ì •ë¦¬ ì‹œì‘")
        print("="*80)
        
        try:
            # 1ë‹¨ê³„: ì˜¤ë˜ëœ ì—ëŸ¬ë¡œê·¸ ì •ë¦¬ (30ì¼ ê¸°ì¤€)
            print("\n1ë‹¨ê³„: ì˜¤ë˜ëœ ì—ëŸ¬ë¡œê·¸ ì •ë¦¬")
            errorlog_cleanup_result = cleanup_old_errorlogs(days_to_keep=30, logger=self.logger)
            
            if errorlog_cleanup_result['success']:
                print(f"ì—ëŸ¬ë¡œê·¸ ì •ë¦¬ ì™„ë£Œ: {len(errorlog_cleanup_result['deleted_folders'])}ê°œ í´ë” ì‚­ì œ")
                if errorlog_cleanup_result['total_size_freed'] > 0:
                    print(f"   â””â”€ ì •ë¦¬ëœ ìš©ëŸ‰: {errorlog_cleanup_result['total_size_freed'] / (1024*1024):.2f} MB")
            else:
                print(f"ì—ëŸ¬ë¡œê·¸ ì •ë¦¬ ì‹¤íŒ¨: {errorlog_cleanup_result['message']}")
            
            # 2ë‹¨ê³„: ì—ëŸ¬ë¡œê·¸ êµ¬ê¸€ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ (ì˜¤ëŠ˜ ë‚ ì§œ ë¡œê·¸ë§Œ)
            print("\n2ë‹¨ê³„: ì—ëŸ¬ë¡œê·¸ êµ¬ê¸€ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ (ì˜¤ëŠ˜ ë‚ ì§œ ë¡œê·¸ë§Œ)")
            errorlog_upload_result = upload_errorlog_to_drive(self.logger)
            
            if errorlog_upload_result['success']:
                print(f"ì˜¤ëŠ˜ ë‚ ì§œ ì—ëŸ¬ë¡œê·¸ ì—…ë¡œë“œ ì™„ë£Œ")
            else:
                print(f"ì—ëŸ¬ë¡œê·¸ ì—…ë¡œë“œ ì‹¤íŒ¨: {errorlog_upload_result['message']}")
            
            print("="*80)
            print("ì—ëŸ¬ë¡œê·¸ ìë™ ì—…ë¡œë“œ ë° ì •ë¦¬ ì™„ë£Œ")
            print("="*80)
            
            self.process.cleanup_result = {
                'errorlog_cleanup': errorlog_cleanup_result,
                'errorlog_upload': errorlog_upload_result
            }
            
        except Exception as e:
            error_msg = f"ì—ëŸ¬ë¡œê·¸ ìë™ ì—…ë¡œë“œ ë° ì •ë¦¬ ì‹¤íŒ¨: {str(e)}"
            print(f"{error_msg}")
            self.logger.error(error_msg)
            self.logger.error(f"ìƒì„¸ ì—ëŸ¬: {traceback.format_exc()}")
        
        print("ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ë‹¨ê³„ ì™„ë£Œ")
        return self
    
    def build(self):
        """ìµœì¢… í”„ë¡œì„¸ìŠ¤ ë°˜í™˜"""
        return self.process

# ì„¤ì • íŒŒì¼ì—ì„œ ì„ ì‚¬ ì •ë³´ ë¡œë“œ
def load_carriers_config():
    """ì„ ì‚¬ ì„¤ì • íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        import json
        config_path = os.path.join(os.getcwd(), 'config', 'carriers.json')
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        # ê¸°ë³¸ê°’ ë°˜í™˜
        return {"carriers": []}

# ì—‘ì…€ ë¡œê·¸ ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ (ìŠ¤ë ˆë“œ ì•ˆì „ì„ ìœ„í•´ Lock ì‚¬ìš©)
excel_log_data = []
excel_log_lock = threading.Lock()

def add_to_excel_log(carrier_name, vessel_name, status, reason, duration):
    """ì—‘ì…€ ë¡œê·¸ì— ê¸°ë¡ ì¶”ê°€ (ì„±ê³µ/ì‹¤íŒ¨ ëª¨ë‘) - ìŠ¤ë ˆë“œ ì•ˆì „"""
    global excel_log_data
    with excel_log_lock:
        now = datetime.now()
        excel_log_data.append({
            'ë‚ ì§œ': now.strftime('%Y/%m/%d/%H/%M/%S'),
            'ì„ ì‚¬': carrier_name,
            'ì„ ë°•': vessel_name,
            'ìƒíƒœ': status,
            'ì‚¬ìœ /ê²°ê³¼': reason,
            'ì†Œìš”ì‹œê°„': f"{duration:.2f}ì´ˆ"
        })

def get_errorlog_folders():
    """ErrorLog í´ë” ë‚´ì˜ ëª¨ë“  ë‚ ì§œë³„ í´ë” ëª©ë¡ ë°˜í™˜"""
    errorlog_base_dir = os.path.join(os.getcwd(), "ErrorLog")
    if not os.path.exists(errorlog_base_dir):
        return []
    
    folders = []
    for item in os.listdir(errorlog_base_dir):
        item_path = os.path.join(errorlog_base_dir, item)
        if os.path.isdir(item_path):
            # YYYY-MM-DD í˜•ì‹ì¸ì§€ í™•ì¸
            try:
                datetime.strptime(item, '%Y-%m-%d')
                folders.append(item)
            except ValueError:
                continue
    
    return sorted(folders)

def upload_errorlog_to_drive(logger):
    """ì—ëŸ¬ë¡œê·¸ë¥¼ êµ¬ê¸€ë“œë¼ì´ë¸Œì— ì—…ë¡œë“œ (ì˜¤ëŠ˜ ë‚ ì§œì˜ _log.xlsx íŒŒì¼ë§Œ)"""
    logger.info("=== ì—ëŸ¬ë¡œê·¸ êµ¬ê¸€ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ ì‹œì‘ ===")
    
    try:
        # ë“œë¼ì´ë¸Œ ì„œë¹„ìŠ¤ ìƒì„±
        service = get_drive_service()
        logger.info("âœ… êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì„œë¹„ìŠ¤ ì—°ê²° ì„±ê³µ")
        
        # ì˜¤ëŠ˜ ë‚ ì§œì˜ ì—ëŸ¬ë¡œê·¸ íŒŒì¼ ì°¾ê¸°
        today = datetime.now()
        today_folder = today.strftime('%Y-%m-%d')
        today_log_file = f"{today.strftime('%Y%m%d')}_log.xlsx"
        
        # ì˜¤ëŠ˜ ë‚ ì§œ í´ë” ê²½ë¡œ
        today_folder_path = os.path.join(os.getcwd(), "ErrorLog", today_folder)
        today_log_path = os.path.join(today_folder_path, today_log_file)
        
        # ì˜¤ëŠ˜ ë‚ ì§œì˜ ë¡œê·¸ íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if not os.path.exists(today_log_path):
            logger.warning(f"âš ï¸ ì˜¤ëŠ˜ ë‚ ì§œ({today_folder})ì˜ ë¡œê·¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {today_log_file}")
            return {
                'success': False,
                'message': f'ì˜¤ëŠ˜ ë‚ ì§œ({today_folder})ì˜ ë¡œê·¸ íŒŒì¼ì´ ì—†ìŒ: {today_log_file}',
                'uploaded_files': [],
                'failed_files': []
            }
        
        logger.info(f"ğŸ“ ì˜¤ëŠ˜ ë‚ ì§œ({today_folder})ì˜ ë¡œê·¸ íŒŒì¼ ë°œê²¬: {today_log_file}")
        
        # ì§€ì •ëœ í´ë” IDì— ë°”ë¡œ ì—…ë¡œë“œ (ErrorLog í´ë” ìƒì„± ë¶ˆí•„ìš”)
        target_folder_id = ERRORLOG_DRIVE_FOLDER_ID
        logger.info(f"ğŸ“ ì§€ì •ëœ í´ë”ì— ë°”ë¡œ ì—…ë¡œë“œ: {target_folder_id}")
        
        # ì˜¤ëŠ˜ ë‚ ì§œì˜ ë¡œê·¸ íŒŒì¼ë§Œ ì—…ë¡œë“œ
        uploaded_files = []
        failed_files = []
        
        try:
            # íŒŒì¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            file_size = os.path.getsize(today_log_path)
            file_modified = datetime.fromtimestamp(os.path.getmtime(today_log_path))
            
            # íŒŒì¼ ì—…ë¡œë“œ
            upload_file_to_drive(service, today_log_path, target_folder_id)
            uploaded_files.append({
                'filename': today_log_file,
                'file_id': 'N/A',
                'size': file_size,
                'modified': file_modified
            })
            
            logger.info(f"âœ… {today_log_file} ì—…ë¡œë“œ ì™„ë£Œ")
            
        except Exception as e:
            failed_files.append({
                'filename': today_log_file,
                'error': str(e)
            })
            logger.error(f"âŒ {today_log_file} ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        
        # ìµœì¢… ê²°ê³¼ ì¶œë ¥
        success_count = len(uploaded_files)
        fail_count = len(failed_files)
        total_files = success_count + fail_count
        
        logger.info("="*60)
        logger.info("ğŸ“Š ì—ëŸ¬ë¡œê·¸ ì—…ë¡œë“œ ê²°ê³¼ ìš”ì•½")
        logger.info("="*60)
        logger.info(f"ì—…ë¡œë“œ ëŒ€ìƒ: {today_log_file}")
        logger.info(f"ì„±ê³µ: {success_count}ê°œ")
        logger.info(f"ì‹¤íŒ¨: {fail_count}ê°œ")
        if total_files > 0:
            success_rate = (success_count / total_files) * 100
            logger.info(f"ì„±ê³µë¥ : {success_rate:.1f}%")
        logger.info("="*60)
        
        return {
            'success': success_count > 0,
            'total_files': total_files,
            'uploaded_files': uploaded_files,
            'failed_files': failed_files,
            'success_count': success_count,
            'fail_count': fail_count
        }
        
    except Exception as e:
        error_msg = f"ì—ëŸ¬ë¡œê·¸ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        logger.error(error_msg)
        logger.error(f"ìƒì„¸ ì—ëŸ¬: {traceback.format_exc()}")
        return {
            'success': False,
            'message': error_msg,
            'uploaded_files': [],
            'failed_files': []
        }

def cleanup_old_errorlogs(days_to_keep=30, logger=None):
    """30ì¼ ê¸°ì¤€ìœ¼ë¡œ ì˜¤ë˜ëœ ì—ëŸ¬ë¡œê·¸ ì •ë¦¬"""
    if logger is None:
        logger = logging.getLogger(__name__)
    
    logger.info("=== ì˜¤ë˜ëœ ì—ëŸ¬ë¡œê·¸ ì •ë¦¬ ì‹œì‘ ===")
    
    try:
        # ê¸°ì¤€ ë‚ ì§œ ê³„ì‚° (30ì¼ ì „)
        cutoff_date = datetime.now() - datetime.timedelta(days=days_to_keep)
        logger.info(f"ğŸ—“ï¸ {days_to_keep}ì¼ ì´ì „ ë°ì´í„° ì •ë¦¬ ê¸°ì¤€: {cutoff_date.strftime('%Y-%m-%d')}")
        
        # ì—ëŸ¬ë¡œê·¸ í´ë”ë“¤ ê°€ì ¸ì˜¤ê¸°
        errorlog_folders = get_errorlog_folders()
        if not errorlog_folders:
            logger.info("ğŸ“ ì •ë¦¬í•  ì—ëŸ¬ë¡œê·¸ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {
                'success': True,
                'deleted_folders': [],
                'total_size_freed': 0
            }
        
        deleted_folders = []
        total_size_freed = 0
        
        for folder_name in errorlog_folders:
            try:
                # í´ë”ëª…ì„ ë‚ ì§œë¡œ íŒŒì‹±
                folder_date = datetime.strptime(folder_name, '%Y-%m-%d')
                
                # ê¸°ì¤€ ë‚ ì§œë³´ë‹¤ ì˜¤ë˜ëœ í´ë”ì¸ì§€ í™•ì¸
                if folder_date < cutoff_date:
                    folder_path = os.path.join(os.getcwd(), "ErrorLog", folder_name)
                    
                    # í´ë” ë‚´ íŒŒì¼ë“¤ì˜ ì´ í¬ê¸° ê³„ì‚°
                    folder_size = 0
                    if os.path.exists(folder_path):
                        for root, dirs, files in os.walk(folder_path):
                            for file in files:
                                file_path = os.path.join(root, file)
                                folder_size += os.path.getsize(file_path)
                    
                    # í´ë” ì‚­ì œ
                    shutil.rmtree(folder_path)
                    deleted_folders.append({
                        'name': folder_name,
                        'date': folder_date.strftime('%Y-%m-%d'),
                        'size': folder_size
                    })
                    total_size_freed += folder_size
                    
                    logger.info(f"ğŸ—‘ï¸ {folder_name} í´ë” ì‚­ì œ ì™„ë£Œ (í¬ê¸°: {folder_size:,} bytes)")
                else:
                    logger.info(f"ğŸ“ {folder_name} í´ë”ëŠ” {days_to_keep}ì¼ ì´ë‚´ë¡œ ìœ ì§€")
                    
            except ValueError as e:
                logger.warning(f"âš ï¸ {folder_name} í´ë”ëª…ì„ ë‚ ì§œë¡œ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")
                continue
            except Exception as e:
                logger.error(f"âŒ {folder_name} í´ë” ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                continue
        
        # ì •ë¦¬ ê²°ê³¼ ì¶œë ¥
        logger.info("="*60)
        logger.info("ğŸ—‘ï¸ ì—ëŸ¬ë¡œê·¸ ì •ë¦¬ ê²°ê³¼ ìš”ì•½")
        logger.info("="*60)
        logger.info(f"ì‚­ì œëœ í´ë” ìˆ˜: {len(deleted_folders)}ê°œ")
        logger.info(f"ì •ë¦¬ëœ ì´ ìš©ëŸ‰: {total_size_freed:,} bytes ({total_size_freed / (1024*1024):.2f} MB)")
        
        if deleted_folders:
            logger.info("\nì‚­ì œëœ í´ë” ëª©ë¡:")
            for folder in deleted_folders:
                logger.info(f"  â””â”€ {folder['name']} ({folder['date']}) - {folder['size']:,} bytes")
        
        logger.info("="*60)
        
        return {
            'success': True,
            'deleted_folders': deleted_folders,
            'total_size_freed': total_size_freed
        }
        
    except Exception as e:
        error_msg = f"ì—ëŸ¬ë¡œê·¸ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        logger.error(error_msg)
        logger.error(f"ìƒì„¸ ì—ëŸ¬: {traceback.format_exc()}")
        return {
            'success': False,
            'message': error_msg,
            'deleted_folders': [],
            'total_size_freed': 0
        }

def save_excel_log(crawling_results, total_duration):
    """ì—‘ì…€ ë¡œê·¸ íŒŒì¼ ì €ì¥ (ìš”ì•½ ì •ë³´ í¬í•¨)"""
    if not excel_log_data:
        return
    
    try:
        # ê¸°ë³¸ ë¡œê·¸ ë°ì´í„°
        df = pd.DataFrame(excel_log_data)
        
        # ìš”ì•½ ì •ë³´ ê³„ì‚°
        success_count = 0
        fail_count = 0
        total_vessels_success = 0
        total_vessels_fail = 0
        
        for carrier_name, result in crawling_results:
            if result['success']:
                success_count += 1
                if 'success_count' in result:
                    total_vessels_success += result['success_count']
                    total_vessels_fail += result.get('fail_count', 0)
            else:
                fail_count += 1
                if 'total_vessels' in result and 'fail_count' in result:
                    total_vessels_success += result.get('success_count', 0)
                    total_vessels_fail += result['fail_count']
        
        # ìš”ì•½ í–‰ ì¶”ê°€
        summary_rows = [
            {'ë‚ ì§œ': '', 'ì„ ì‚¬': '', 'ì„ ë°•': '', 'ìƒíƒœ': '', 'ì‚¬ìœ /ê²°ê³¼': '', 'ì†Œìš”ì‹œê°„': ''},
            {'ë‚ ì§œ': '', 'ì„ ì‚¬': '=== í¬ë¡¤ë§ ê²°ê³¼ ìš”ì•½ ===', 'ì„ ë°•': '', 'ìƒíƒœ': '', 'ì‚¬ìœ /ê²°ê³¼': '', 'ì†Œìš”ì‹œê°„': ''},
            {'ë‚ ì§œ': '', 'ì„ ì‚¬': f'ì´ {len(crawling_results)}ê°œ ì„ ì‚¬ ì¤‘', 'ì„ ë°•': '', 'ìƒíƒœ': '', 'ì‚¬ìœ /ê²°ê³¼': '', 'ì†Œìš”ì‹œê°„': ''},
            {'ë‚ ì§œ': '', 'ì„ ì‚¬': f'ì„±ê³µ: {success_count}ê°œ', 'ì„ ë°•': '', 'ìƒíƒœ': '', 'ì‚¬ìœ /ê²°ê³¼': '', 'ì†Œìš”ì‹œê°„': ''},
            {'ë‚ ì§œ': '', 'ì„ ì‚¬': f'ì‹¤íŒ¨: {fail_count}ê°œ', 'ì„ ë°•': '', 'ìƒíƒœ': '', 'ì‚¬ìœ /ê²°ê³¼': '', 'ì†Œìš”ì‹œê°„': ''},
            {'ë‚ ì§œ': '', 'ì„ ì‚¬': f'ì´ ì†Œìš”ì‹œê°„: {total_duration:.2f}ì´ˆ', 'ì„ ë°•': '', 'ìƒíƒœ': '', 'ì‚¬ìœ /ê²°ê³¼': '', 'ì†Œìš”ì‹œê°„': ''},
            {'ë‚ ì§œ': '', 'ì„ ì‚¬': '', 'ì„ ë°•': '', 'ìƒíƒœ': '', 'ì‚¬ìœ /ê²°ê³¼': '', 'ì†Œìš”ì‹œê°„': ''},
            {'ë‚ ì§œ': '', 'ì„ ì‚¬': '=== ì„ ë°•ë³„ ìƒì„¸ ê²°ê³¼ ===', 'ì„ ë°•': '', 'ìƒíƒœ': '', 'ì‚¬ìœ /ê²°ê³¼': '', 'ì†Œìš”ì‹œê°„': ''},
            {'ë‚ ì§œ': '', 'ì„ ì‚¬': f'ì´ ì„ ë°•: {total_vessels_success + total_vessels_fail}ê°œ', 'ì„ ë°•': '', 'ìƒíƒœ': '', 'ì‚¬ìœ /ê²°ê³¼': '', 'ì†Œìš”ì‹œê°„': ''},
            {'ë‚ ì§œ': '', 'ì„ ì‚¬': f'ì„±ê³µ: {total_vessels_success}ê°œ', 'ì„ ë°•': '', 'ìƒíƒœ': '', 'ì‚¬ìœ /ê²°ê³¼': '', 'ì†Œìš”ì‹œê°„': ''},
            {'ë‚ ì§œ': '', 'ì„ ì‚¬': f'ì‹¤íŒ¨: {total_vessels_fail}ê°œ', 'ì„ ë°•': '', 'ìƒíƒœ': '', 'ì‚¬ìœ /ê²°ê³¼': '', 'ì†Œìš”ì‹œê°„': ''}
        ]
        
        # ìš”ì•½ í–‰ì„ DataFrameì— ì¶”ê°€
        summary_df = pd.DataFrame(summary_rows)
        final_df = pd.concat([df, summary_df], ignore_index=True)
        
        today_str = datetime.now().strftime('%Y%m%d')
        excel_filename = f"{today_str}_log.xlsx"
        excel_path = os.path.join(today_log_dir, excel_filename)
        
        final_df.to_excel(excel_path, index=False, engine='openpyxl')
        print(f"âœ… ì—‘ì…€ ë¡œê·¸ ì €ì¥ ì™„ë£Œ: {excel_path}")
        
    except Exception as e:
        print(f"âŒ ì—‘ì…€ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        logging.error(f"ì—‘ì…€ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {str(e)}")

def run_crawler_with_error_handling(crawler_name, crawler_instance):
    """í¬ë¡¤ëŸ¬ë¥¼ ì‹¤í–‰í•˜ê³  ì—ëŸ¬ë¥¼ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
    logger = logging.getLogger(__name__)
    
    try:
        logger.info(f"=== {crawler_name} í¬ë¡¤ë§ ì‹œì‘ ===")
        start_time = datetime.now()
        
        # ì²« ë²ˆì§¸ ì‹œë„
        result = crawler_instance.run()
        
        # ì‹¤íŒ¨í•œ ì„ ë°•ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì¬ì‹œë„
        retry_result = None
        if hasattr(crawler_instance, 'failed_vessels') and crawler_instance.failed_vessels:
                failed_vessels = crawler_instance.failed_vessels.copy()
                failed_reasons = getattr(crawler_instance, 'failed_reasons', {}).copy()
                
                logger.info(f"=== {crawler_name} ì‹¤íŒ¨í•œ ì„ ë°• ì¬ì‹œë„ ì‹œì‘ ===")
                logger.info(f"ì¬ì‹œë„ ëŒ€ìƒ ì„ ë°•: {', '.join(failed_vessels)}")
                logger.info(f"ì¬ì‹œë„ ëŒ€ìƒ ê°œìˆ˜: {len(failed_vessels)}ê°œ")
                
                # ì‹¤íŒ¨í•œ ì„ ë°•ë“¤ë§Œ ì¬ì‹œë„
                retry_result = crawler_instance.retry_failed_vessels(failed_vessels)
                
                if retry_result:
                    logger.info(f"=== {crawler_name} ì¬ì‹œë„ ì™„ë£Œ ===")
                    logger.info(f"ì¬ì‹œë„ ì„±ê³µ: {retry_result.get('retry_success', 0)}ê°œ")
                    logger.info(f"ì¬ì‹œë„ ì‹¤íŒ¨: {retry_result.get('retry_fail', 0)}ê°œ")
                    logger.info(f"ì¬ì‹œë„ í›„ ìµœì¢… ì„±ê³µ: {retry_result.get('final_success', 0)}ê°œ")
                    logger.info(f"ì¬ì‹œë„ í›„ ìµœì¢… ì‹¤íŒ¨: {retry_result.get('final_fail', 0)}ê°œ")
                    
                    if 'note' in retry_result:
                        logger.info(f"ì¬ì‹œë„ ì°¸ê³ ì‚¬í•­: {retry_result['note']}")
                else:
                    logger.warning(f"=== {crawler_name} ì¬ì‹œë„ ì‹¤íŒ¨ ===")
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        # í¬ë¡¤ëŸ¬ì— ì„±ê³µ/ì‹¤íŒ¨ ì¹´ìš´íŠ¸ê°€ ìˆëŠ” ê²½ìš° ì„ ë°•ë³„ ê²°ê³¼ í™•ì¸
        if hasattr(crawler_instance, 'success_count') and hasattr(crawler_instance, 'fail_count'):
            # ì‹¤ì œ ì„ ë°• ëŒ€ìˆ˜ëŠ” vessel_name_listì˜ ê¸¸ì´ë¡œ ê³„ì‚°
            total_vessels = len(getattr(crawler_instance, 'vessel_name_list', []))
            success_count = getattr(crawler_instance, 'success_count', 0)
            fail_count = getattr(crawler_instance, 'fail_count', 0)
            failed_vessels = getattr(crawler_instance, 'failed_vessels', [])
            failed_reasons = getattr(crawler_instance, 'failed_reasons', {})
            
            # ì„±ê³µí•œ ì„ ë°•ë“¤ì„ ì—‘ì…€ ë¡œê·¸ì— ê¸°ë¡
            if hasattr(crawler_instance, 'vessel_name_list'):
                for vessel_name in crawler_instance.vessel_name_list:
                    if vessel_name not in failed_vessels:
                        vessel_duration = getattr(crawler_instance, 'get_vessel_duration', lambda x: duration)(vessel_name)
                        add_to_excel_log(crawler_name, vessel_name, "ì„±ê³µ", "í¬ë¡¤ë§ ì™„ë£Œ", vessel_duration)
            
            # ì‹¤íŒ¨í•œ ì„ ë°•ë“¤ì„ ì—‘ì…€ ë¡œê·¸ì— ê¸°ë¡
            for vessel_name in failed_vessels:
                reason = failed_reasons.get(vessel_name, "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
                vessel_duration = getattr(crawler_instance, 'get_vessel_duration', lambda x: duration)(vessel_name)
                add_to_excel_log(crawler_name, vessel_name, "ì‹¤íŒ¨", reason, vessel_duration)
            
            # ì¬ì‹œë„ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš° ìµœì¢… ê²°ê³¼ ë°˜ì˜
            final_success_count = success_count
            final_fail_count = fail_count
            final_failed_vessels = failed_vessels.copy()
            
            if retry_result:
                final_success_count = retry_result.get('final_success', success_count)
                final_fail_count = retry_result.get('final_fail', fail_count)
                # ì¬ì‹œë„ í›„ ìµœì¢… ì‹¤íŒ¨í•œ ì„ ë°•ë“¤ ì—…ë°ì´íŠ¸
                if 'final_failed_vessels' in retry_result:
                    final_failed_vessels = retry_result['final_failed_vessels']
            
            # ì„ ë°• ì¤‘ í•˜ë‚˜ë¼ë„ ì‹¤íŒ¨í•˜ë©´ ì„ ì‚¬ë„ ì‹¤íŒ¨ë¡œ ë¶„ë¥˜
            if final_fail_count > 0:
                logger.error(f"=== {crawler_name} í¬ë¡¤ë§ ì‹¤íŒ¨ (ì†Œìš”ì‹œê°„: {duration:.2f}ì´ˆ) ===")
                logger.error(f"ì„ ë°• ì‹¤íŒ¨ë¡œ ì¸í•œ ì„ ì‚¬ ì‹¤íŒ¨: ì´ {total_vessels}ê°œ ì„ ë°• ì¤‘ ì„±ê³µ {final_success_count}ê°œ, ì‹¤íŒ¨ {final_fail_count}ê°œ")
                if final_failed_vessels:
                    logger.error(f"ì‹¤íŒ¨í•œ ì„ ë°•: {', '.join(final_failed_vessels)}")
                
                return {
                    'success': False,
                    'duration': duration,
                    'start_time': start_time,
                    'end_time': end_time,
                    'total_vessels': total_vessels,
                    'success_count': final_success_count,
                    'fail_count': final_fail_count,
                    'failed_vessels': final_failed_vessels,
                    'error': f'ì„ ë°• ì‹¤íŒ¨ë¡œ ì¸í•œ ì„ ì‚¬ ì‹¤íŒ¨ (ì‹¤íŒ¨í•œ ì„ ë°•: {", ".join(final_failed_vessels)})'
                }
            else:
                logger.info(f"=== {crawler_name} í¬ë¡¤ë§ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {duration:.2f}ì´ˆ) ===")
                logger.info(f"{crawler_name} ìƒì„¸ ê²°ê³¼: ì´ {total_vessels}ê°œ ì„ ë°• ì¤‘ ì„±ê³µ {final_success_count}ê°œ, ì‹¤íŒ¨ {final_fail_count}ê°œ")
                
                return {
                    'success': True,
                    'duration': duration,
                    'start_time': start_time,
                    'end_time': end_time,
                    'total_vessels': total_vessels,
                    'success_count': final_success_count,
                    'fail_count': final_fail_count,
                    'failed_vessels': final_failed_vessels
                }
        else:
            # ì„±ê³µ/ì‹¤íŒ¨ ì¹´ìš´íŠ¸ê°€ ì—†ëŠ” ê²½ìš° ê¸°ì¡´ ë¡œì§ ì‚¬ìš©
            if result:
                logger.info(f"=== {crawler_name} í¬ë¡¤ë§ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {duration:.2f}ì´ˆ) ===")
                return {
                    'success': True,
                    'duration': duration,
                    'start_time': start_time,
                    'end_time': end_time
                }
            else:
                logger.error(f"=== {crawler_name} í¬ë¡¤ë§ ì‹¤íŒ¨ (ì†Œìš”ì‹œê°„: {duration:.2f}ì´ˆ) ===")
                return {
                    'success': False,
                    'duration': duration,
                    'start_time': start_time,
                    'end_time': end_time,
                    'error': 'í¬ë¡¤ëŸ¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ'
                }
            
    except Exception as e:
        end_time = datetime.now()
        duration = (end_time - start_time) if 'start_time' in locals() else 0
        
        logger.error(f"=== {crawler_name} í¬ë¡¤ë§ ì‹¤íŒ¨ ===")
        logger.error(f"ì—ëŸ¬ ë©”ì‹œì§€: {str(e)}")
        logger.error(f"ìƒì„¸ ì—ëŸ¬: {traceback.format_exc()}")
        
        return {
            'success': False,
            'duration': duration.total_seconds() if hasattr(duration, 'total_seconds') else 0,
            'start_time': start_time if 'start_time' in locals() else None,
            'end_time': end_time,
            'error': str(e),
            'traceback': traceback.format_exc()
        }

def try_run_carrier(crawler_name, constructor, results_list):
    """í¬ë¡¤ëŸ¬ ì¸ìŠ¤í„´ìŠ¤í™” ë‹¨ê³„ì—ì„œì˜ ì˜ˆì™¸ë„ ì¡ì•„ì„œ ë‹¤ìŒ ì„ ì‚¬ë¡œ ë„˜ì–´ê°€ë„ë¡ ì²˜ë¦¬"""
    logger = logging.getLogger(__name__)
    try:
        # í¬ë¡¤ëŸ¬ íŒ©í† ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        instance = CrawlerFactory.create_crawler(crawler_name)
    except Exception as e:
        end_time = datetime.now()
        logger.error(f"=== {crawler_name} í¬ë¡¤ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨ ===")
        logger.error(f"ì—ëŸ¬ ë©”ì‹œì§€: {str(e)}")
        logger.error(f"ìƒì„¸ ì—ëŸ¬: {traceback.format_exc()}")
        results_list.append((crawler_name, {
            'success': False,
            'duration': 0,
            'start_time': None,
            'end_time': end_time,
            'error': str(e),
            'traceback': traceback.format_exc()
        }))
        return
    # ì¸ìŠ¤í„´ìŠ¤ ìƒì„±ì— ì„±ê³µí•˜ë©´ ì‹¤í–‰
    result = run_crawler_with_error_handling(crawler_name, instance)
    results_list.append((crawler_name, result))

def run_carrier_parallel(crawler_name):
    """ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰í•  í¬ë¡¤ëŸ¬ í•¨ìˆ˜"""
    logger = logging.getLogger(__name__)
    try:
        # í¬ë¡¤ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        instance = CrawlerFactory.create_crawler(crawler_name)
        # í¬ë¡¤ëŸ¬ ì‹¤í–‰
        result = run_crawler_with_error_handling(crawler_name, instance)
        return crawler_name, result
    except Exception as e:
        end_time = datetime.now()
        logger.error(f"=== {crawler_name} í¬ë¡¤ëŸ¬ ì‹¤í–‰ ì‹¤íŒ¨ ===")
        logger.error(f"ì—ëŸ¬ ë©”ì‹œì§€: {str(e)}")
        logger.error(f"ìƒì„¸ ì—ëŸ¬: {traceback.format_exc()}")
        return crawler_name, {
            'success': False,
            'duration': 0,
            'start_time': None,
            'end_time': end_time,
            'error': str(e),
            'traceback': traceback.format_exc()
        }

if __name__ == "__main__":
    print("ë¹Œë” íŒ¨í„´ì„ ì‚¬ìš©í•œ ìŠ¤ë ˆë“œ ê¸°ë°˜ ë³‘ë ¬ í¬ë¡¤ë§ ì‹œì‘!")
    print("="*80)
    
    try:
        # ë¹Œë” íŒ¨í„´ì„ ì‚¬ìš©í•˜ì—¬ í¬ë¡¤ë§ í”„ë¡œì„¸ìŠ¤ êµ¬ì„± ë° ì‹¤í–‰
        crawling_process = (CrawlingProcessBuilder()
            .setup_environment()           # 1ë‹¨ê³„: í™˜ê²½ ì„¤ì •
            .configure_threading(2)       # 2ë‹¨ê³„: ìŠ¤ë ˆë“œ ì„¤ì • (2ê°œ)
            .add_carriers()               # 3ë‹¨ê³„: ì„ ì‚¬ ì„¤ì •
            .execute_crawling()           # 4ë‹¨ê³„: í¬ë¡¤ë§ ì‹¤í–‰
            .generate_reports()           # 5ë‹¨ê³„: ë³´ê³ ì„œ ìƒì„±
            .upload_to_drive()            # 6ë‹¨ê³„: ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ
            .cleanup_resources()          # 7ë‹¨ê³„: ë¦¬ì†ŒìŠ¤ ì •ë¦¬
            .build())                     # ìµœì¢… í”„ë¡œì„¸ìŠ¤ ë°˜í™˜
        
        print("\n" + "="*80)
        print("ë¹Œë” íŒ¨í„´ì„ ì‚¬ìš©í•œ í¬ë¡¤ë§ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ!")
        print("="*80)
        
        # ìµœì¢… ê²°ê³¼ ìš”ì•½
        print(f"ì´ ì†Œìš”ì‹œê°„: {crawling_process.total_duration:.2f}ì´ˆ")
        print(f"ì„±ê³µ: {crawling_process.success_count}ê°œ ì„ ì‚¬")
        print(f"ì‹¤íŒ¨: {crawling_process.fail_count}ê°œ ì„ ì‚¬")
        
        if crawling_process.total_vessels_success > 0 or crawling_process.total_vessels_fail > 0:
            print(f"ì„ ë°•ë³„ - ì„±ê³µ: {crawling_process.total_vessels_success}ê°œ, ì‹¤íŒ¨: {crawling_process.total_vessels_fail}ê°œ")
        
        print("="*80)
        
    except Exception as e:
        print(f"í¬ë¡¤ë§ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        print(f"ìƒì„¸ ì—ëŸ¬: {traceback.format_exc()}")
        sys.exit(1)

    

    